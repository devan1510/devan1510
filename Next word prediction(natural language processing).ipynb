{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33a137f0-d15f-493a-a9e7-1b1c90dd7639",
   "metadata": {},
   "source": [
    "# Next word prediction with long short-term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b6e46cc-0e01-4034-8042-b31444ecb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries #\n",
    "# tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,Input\n",
    "# text preprocessing imports \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# regular expression for text preprocessing normalization\n",
    "import regex as re\n",
    "# imports for exploratory data analysis and loading dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdce8bb2-21b5-4e0c-9323-664b010e9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the text dataset\n",
    "file_path= \"C:\\\\recommender systems\\\\pizza.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4392d5c-4609-4d6d-abbb-d7c2cd4aa22d",
   "metadata": {},
   "source": [
    "# text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2ee4538-3dbe-40d5-9e70-289a6b32215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove delimiters like('.', '?', and '!') from the sentences using regex\n",
    "# use a list comprehension to extract all the sentences\n",
    "sentences = [sentence.strip() for sentence in re.split(\n",
    "        r'(?<=[.!?])\\s+', text) if sentence.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "939f186e-e28a-45ae-bbdc-0a58880d945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text data\n",
    "tokenizer = Tokenizer(num_words= 686)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "total_words = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98523f6c-9b64-41ed-9de5-bbe2d3de3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences\n",
    "input_seq = []\n",
    "for line in sentences:\n",
    "    tokens = tokenizer.texts_to_sequences([line])[0]\n",
    "    for word in range(1, len(tokens)):\n",
    "        n_gram_seq = tokens[:word+1]\n",
    "        input_seq.append(n_gram_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21135d7c-7de3-4bb7-abaa-3eba7e515851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences and split into predictors and label\n",
    "max_sequence_len = max([len(seq) for seq in input_seq])\n",
    "input_seq = np.array(pad_sequences(\n",
    "    input_seq, maxlen=max_sequence_len, padding='post'))\n",
    "X, y = input_seq[:, :-1], input_seq[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8171a9c-3f36-4dae-9999-42b7e0ea96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target data to one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e0cbe-4eda-4955-aae1-0484717e7e86",
   "metadata": {},
   "source": [
    "# model preparation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdc96d64-a452-459c-9d0a-6f83caef3fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# use an LSTM (Long Short-Term Memory) layer with 8 units\n",
    "#A Dense layer with softmax activation\n",
    "# set vocab_size and embedding dimension\n",
    "vocab_size = 686  \n",
    "embedding_dim = 128\n",
    "# develop the mdoel\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dense(total_words, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "063c9b20-46a1-4831-82c3-51b771be59c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83d0a6cd-2b68-44f4-8d50-61730904aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "549e72eb-16d0-4128-9269-13d8db11a99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.4976 - loss: 6.2646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f8c165a9d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X, y, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a2f8aef-627e-4810-98e6-ef74b727cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "Predicted index is padding\n",
      "Pizza have different \n"
     ]
    }
   ],
   "source": [
    "# generate predictions for the next word\n",
    "text = \"Pizza have different \"\n",
    "next_word = 1\n",
    "# Assume seed_text is initialized and you are generating predictions\n",
    "for _ in range(next_word):\n",
    "    tokens = tokenizer.texts_to_sequences([text])[0]  # Generate token list\n",
    "    tokens = pad_sequences([tokens], maxlen=max_sequence_len-1, padding='post')\n",
    "    predicted_probs = model.predict(tokens)\n",
    "    predicted_index = np.argmax(predicted_probs)\n",
    "    \n",
    "    if predicted_index > 0:  # Check to avoid the padding index\n",
    "        predicted_word = tokenizer.index_word[predicted_index]\n",
    "        text += \" \" + predicted_word\n",
    "    else:\n",
    "        print(\"Predicted index is padding\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74cdbd-e804-49f9-a898-13df9ecc41b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
